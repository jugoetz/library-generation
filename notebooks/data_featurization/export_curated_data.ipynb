{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# SynFerm data preparation\n",
    "#### Targets:\n",
    "- Import experiment, representation, and target data from DB\n",
    "- Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(pathlib.Path().resolve().parents[1]))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.util.db_utils import SynFermDatabaseConnection\n",
    "from src.definitions import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = SynFermDatabaseConnection()  # we will use this for various simple queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we only select valid reactions by using the INNER JOIN with the labels table\n",
    "res = con.con.execute('SELECT e.id, r.I_long, r.M_long, r.T_long, r.product_A_smiles, r.I_smiles, r.M_smiles, r.T_smiles, r.reaction_smiles, r.reaction_smiles_atom_mapped, l.binary_A, l.binary_B, l.binary_C, l.binary_D, l.binary_E, l.binary_F, l.binary_G, l.binary_H, l.scaled_A, l.scaled_B, l.scaled_C, l.scaled_D, l.scaled_E, l.scaled_F, l.scaled_G, l.scaled_H, l.\"major_A-C\" FROM experiments e LEFT JOIN representations r on e.id = r.experiment_id INNER JOIN labels l on e.id = l.experiment_id;').fetchall()\n",
    "\n",
    "columns = [\"experiment_id\", \"I_long\", \"M_long\", \"T_long\", \"product_A_smiles\", \"I_smiles\", \"M_smiles\", \"T_smiles\", \"reaction_smiles\", \"reaction_smiles_atom_mapped\", \"binary_A\", \"binary_B\", \"binary_C\", \"binary_D\", \"binary_E\", \"binary_F\", \"binary_G\", \"binary_H\", \"scaled_A\", \"scaled_B\", \"scaled_C\", \"scaled_D\", \"scaled_E\", \"scaled_F\", \"scaled_G\", \"scaled_H\", \"major_A-C\"]\n",
    "df = pd.DataFrame(res, columns=columns)\n",
    "print(f'Number of reactions (in total): {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doublecheck we don't have missing values\n",
    "df['scaled_A'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Aggregate duplicates\n",
    "For training, we want to remove duplicates from out data.\n",
    "To aggregate we follow these steps:\n",
    "1. Take the mean of the scaled values\n",
    "2. From the mean scaled values, calculate the binary labels and the major_A-C label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many duplicates are there?\n",
    "df[\"product_A_smiles\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate duplicates\n",
    "group = df.groupby([\"I_long\", \"M_long\", \"T_long\", \"product_A_smiles\", \"I_smiles\", \"M_smiles\", \"T_smiles\", \"reaction_smiles\", \"reaction_smiles_atom_mapped\"])\n",
    "\n",
    "# take the mean of the scaled values\n",
    "scaled_responses = group[[f\"scaled_{i}\" for i in \"ABCDEFGH\"]].mean()\n",
    "\n",
    "# reassign the binary labels\n",
    "binary_responses = scaled_responses.applymap(lambda x: 1 if x > 0 else 0).rename(columns={f\"scaled_{i}\": f\"binary_{i}\" for i in \"ABCDEFGH\"})\n",
    "\n",
    "# reassign the major_A-C label\n",
    "major = scaled_responses[[f\"scaled_{i}\" for i in \"ABC\"]].idxmax(axis=1).str.strip(\"scaled_\").rename(\"major_A-C\")\n",
    "major.loc[scaled_responses[[f\"scaled_{i}\" for i in \"ABC\"]].sum(axis=1) == 0] = \"no_product\"\n",
    "\n",
    "# merge the results\n",
    "exp_nr = group[\"experiment_id\"].agg(lambda x: x if len(x) == 1 else \"/\".join([str(i) for i in x]))\n",
    "df = pd.merge(exp_nr, binary_responses, left_index=True, right_index=True).merge(scaled_responses, left_index=True, right_index=True).merge(major, left_index=True, right_index=True).reset_index()\n",
    "# length should be original length minus number of duplicates\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.binary_A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Export\n",
    "Now we have a cleaned dataset. Export to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to CSV, with timestamp\n",
    "df.to_csv(DATA_DIR / \"curated_data\" / f\"synferm_dataset_{datetime.datetime.today().strftime('%Y-%m-%d')}_{len(df)}records.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Export the same data as hierarchically nested JSON (for d3.js visualizations)\n",
    "Note: takes a few minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nested dictionary for JSON export\n",
    "res = {\"name\": \"synfermdata\", \"children\": []}\n",
    "\n",
    "for i in df[\"I_long\"].unique():\n",
    "    print(i)  # show progress\n",
    "    res[\"children\"].append({\"name\": i, \"children\": []})\n",
    "    for m in df.loc[df[\"I_long\"] == i, \"M_long\"].unique():\n",
    "        res[\"children\"][-1][\"children\"].append({\"name\": m, \"children\": []})\n",
    "        for t in df.loc[(df[\"I_long\"] == i) & (df[\"M_long\"] == m), \"T_long\"].unique():\n",
    "            values = df.loc[(df[\"I_long\"] == i) & (df[\"M_long\"] == m) & (df[\"T_long\"] == t), [\"scaled_A\", 'scaled_B', \"scaled_C\"]].values.flatten().tolist()\n",
    "            res[\"children\"][-1][\"children\"][-1][\"children\"].append(\n",
    "                {\"name\": t, \"children\": \n",
    "                    [{\"name\": \"A\", \"value\": values[0]}, {\"name\": \"B\", \"value\": values[1]}, {\"name\": \"C\", \"value\": values[2]}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to JSON\n",
    "with open(DATA_DIR / \"curated_data\" / f\"synferm_dataset_{datetime.datetime.today().strftime('%Y-%m-%d')}_{len(df)}records.json\", \"w\") as outfile:\n",
    "    json.dump(res, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
