{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# SynFerm data preparation\n",
    "#### Targets:\n",
    "- Import experiment, representation, and target data from db\n",
    "- Export to CSV.\n",
    "  The CSV should contain the following columns:\n",
    "  `['I_long', 'M_long', 'T_long', 'product_A_smiles', 'I_smiles', 'M_smiles', 'T_smiles', 'reaction_smiles', 'reaction_smiles_atom_mapped', 'experiment_id', 'binary_A', 'binary_B', 'binary_C', 'binary_D', 'binary_E', 'binary_F', 'binary_G', 'binary_H', 'scaled_A', 'scaled_B', 'scaled_C', 'scaled_D', 'scaled_E', 'scaled_F', 'scaled_G', 'scaled_H', 'major_A-C']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(pathlib.Path().resolve().parents[1]))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.util.db_utils import SynFermDatabaseConnection\n",
    "from src.definitions import DATA_DIR\n",
    "from src.library_design.reaction_generator import SFReactionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = SynFermDatabaseConnection()  # we will use this for various simple queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we only select valid reactions by using the INNER JOIN with the labels table\n",
    "# also note that this means that if anything should still change about the data set, the labels have to be regenerated before using this!\n",
    "res = con.con.execute(\"\"\"\n",
    "SELECT e.id, e.initiator_long as I_long, e.monomer_long as M_long, e.terminator_long as T_long, e.product_A_smiles, b_i.SMILES as I_smiles, b_m.SMILES as M_smiles, b_t.SMILES as T_smiles, l.binary_A, l.binary_B, l.binary_C, l.binary_D, l.binary_E, l.binary_F, l.binary_G, l.binary_H, l.scaled_A, l.scaled_B, l.scaled_C, l.scaled_D, l.scaled_E, l.scaled_F, l.scaled_G, l.scaled_H, l.\"major_A-C\"\n",
    "FROM experiments e\n",
    "    LEFT JOIN building_blocks b_i on e.initiator_long = b_i.long\n",
    "    LEFT JOIN building_blocks b_m on e.monomer_long = b_m.long\n",
    "    LEFT JOIN building_blocks b_t on e.terminator_long = b_t.long\n",
    "    INNER JOIN labels l on e.id = l.experiment_id;\n",
    "\"\"\").fetchall()\n",
    "\n",
    "columns = [\"experiment_id\", \"I_long\", \"M_long\", \"T_long\", \"product_A_smiles\", \"I_smiles\", \"M_smiles\", \"T_smiles\", \"binary_A\", \"binary_B\", \"binary_C\", \"binary_D\", \"binary_E\", \"binary_F\", \"binary_G\", \"binary_H\", \"scaled_A\", \"scaled_B\", \"scaled_C\", \"scaled_D\", \"scaled_E\", \"scaled_F\", \"scaled_G\", \"scaled_H\", \"major_A-C\"]\n",
    "df = pd.DataFrame(res, columns=columns)\n",
    "print(f'Number of reactions (in total): {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reaction_smiles(initiator, monomer, terminator, product):\n",
    "    \"\"\"Form unmapped, plain reactionSMILES\"\"\"\n",
    "    return f\"{initiator}.{monomer}.{terminator}>>{product}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plain reactionSMILES (not desalted or anything)\n",
    "reaction_smiles = [make_reaction_smiles(row[\"I_smiles\"], row[\"M_smiles\"], row[\"T_smiles\"], row[\"product_A_smiles\"]) for i, row in df.iterrows()]\n",
    "len(reaction_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reaction_smiles\"] = reaction_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = SFReactionGenerator()\n",
    "# we wrap the generator to catch errors\n",
    "def get_reaction_smiles(x):\n",
    "    try:\n",
    "        return gen.get_reaction_smiles(x)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        print(x)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate atom-mapped reactionSMILES (~15 min)\n",
    "df[\"reaction_smiles_atom_mapped\"] = df[\"product_A_smiles\"].apply(get_reaction_smiles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doublecheck we don't have missing values\n",
    "df['scaled_A'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check we don't have missing features\n",
    "df['reaction_smiles_atom_mapped'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Aggregate duplicates\n",
    "For training, we want to remove duplicates from out data.\n",
    "To aggregate we follow these steps:\n",
    "1. Take the mean of the scaled values\n",
    "2. From the mean scaled values, calculate the binary labels and the major_A-C label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate duplicates\n",
    "group = df.groupby([\"I_long\", \"M_long\", \"T_long\", \"product_A_smiles\", \"I_smiles\", \"M_smiles\", \"T_smiles\", \"reaction_smiles\", \"reaction_smiles_atom_mapped\"])\n",
    "\n",
    "# take the mean of the scaled values\n",
    "scaled_responses = group[[f\"scaled_{i}\" for i in \"ABCDEFGH\"]].mean()\n",
    "\n",
    "# reassign the binary labels\n",
    "binary_responses = scaled_responses.applymap(lambda x: 1 if x > 0 else 0).rename(columns={f\"scaled_{i}\": f\"binary_{i}\" for i in \"ABCDEFGH\"})\n",
    "\n",
    "# reassign the major_A-C label\n",
    "major = scaled_responses[[f\"scaled_{i}\" for i in \"ABC\"]].idxmax(axis=1).str.strip(\"scaled_\").rename(\"major_A-C\")\n",
    "major.loc[scaled_responses[[f\"scaled_{i}\" for i in \"ABC\"]].sum(axis=1) == 0] = \"no_product\"\n",
    "\n",
    "# merge the results\n",
    "exp_nr = group[\"experiment_id\"].agg(lambda x: x if len(x) == 1 else \"/\".join([str(i) for i in x]))\n",
    "df_clean = pd.merge(exp_nr, binary_responses, left_index=True, right_index=True)\\\n",
    "    .merge(scaled_responses, left_index=True, right_index=True)\\\n",
    "    .merge(major, left_index=True, right_index=True)\\\n",
    "    .reset_index()[['I_long', 'M_long', 'T_long', 'product_A_smiles', 'I_smiles', 'M_smiles', 'T_smiles', 'reaction_smiles', 'reaction_smiles_atom_mapped', 'experiment_id', 'binary_A', 'binary_B', 'binary_C', 'binary_D', 'binary_E', 'binary_F', 'binary_G', 'binary_H', 'scaled_A', 'scaled_B', 'scaled_C', 'scaled_D', 'scaled_E', 'scaled_F', 'scaled_G', 'scaled_H', 'major_A-C']]\n",
    "# length should be original length minus number of duplicates\n",
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many positives (ratio) for A?\n",
    "df_clean.binary_A.sum() / len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many positives (ratio) for B?\n",
    "df_clean.binary_B.sum() / len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many positives (ratio) for C?\n",
    "df_clean.binary_C.sum() / len(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Export\n",
    "Now we have a cleaned dataset. Export to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to CSV, with timestamp\n",
    "df_clean.to_csv(DATA_DIR / \"curated_data\" / f\"synferm_dataset_{datetime.datetime.today().strftime('%Y-%m-%d')}_{len(df_clean)}records.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
