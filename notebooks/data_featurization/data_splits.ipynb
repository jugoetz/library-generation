{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Splits\n",
    "\n",
    "We want to split the SynFerm data set into train and test data.\n",
    "For now, we define a 0D and a 1D split.\n",
    "\n",
    "### 0D Split\n",
    "For the 0D split, we use a random train-test split.\n",
    "Due to the size of the data, we do not need to use CV or repeated sampling.\n",
    "We use a 90/10 split.\n",
    "\n",
    "### 1D Split\n",
    "For the 1D split, we provide use a (1D) GroupShuffleSplit.\n",
    "Each individual split will be 90/10 train/test (of groups not samples!).\n",
    "As groups, we use either initiator, monomer, or terminator.\n",
    "For each of the 3 building blocks, we provide 3 splits for a total of 9 splits."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", \"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "\n",
    "from src.definitions import DATA_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:27:18.902327Z",
     "start_time": "2023-07-23T14:27:18.899575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(DATA_DIR / \"curated_data\" / \"synferm_dataset_2023-07-20_40433records.csv\")\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:09:08.976642Z",
     "start_time": "2023-07-23T14:09:08.641278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   experiment_id I_long  M_long     T_long  \\\n0          10578  Ph023  Mon017   TerTH010   \n1          10579  Ph023  Mon017   TerTH026   \n2          10580  Ph023  Mon017   TerTH015   \n3          10581  Ph023  Mon017   TerTH020   \n4          10584  Ph023  Mon017  TerABT001   \n\n                                    product_A_smiles  \\\n0  CC(C)(C)OC(=O)CC[C@@H](Cc1nnc(C=Cc2ccccc2)s1)N...   \n1  CC(C)(C)OC(=O)CC[C@@H](Cc1nnc(-c2cn[nH]c2)s1)N...   \n2  CC(C)(C)OC(=O)CC[C@@H](Cc1nnc(-c2cc(Cl)cc(Cl)c...   \n3  CN(C)c1cccc(-c2nnc(C[C@H](CCC(=O)OC(C)(C)C)NC(...   \n4  CC(C)(C)OC(=O)CC[C@@H](Cc1nc2ccccc2s1)NC(=O)c1...   \n\n                            I_smiles  \\\n0  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]   \n1  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]   \n2  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]   \n3  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]   \n4  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]   \n\n                                            M_smiles  \\\n0  CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O   \n1  CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O   \n2  CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O   \n3  CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O   \n4  CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O   \n\n                     T_smiles  \\\n0     Cl.NNC(=S)/C=C/c1ccccc1   \n1        Cl.NNC(=S)c1cn[nH]c1   \n2  Cl.NNC(=S)c1cc(Cl)cc(Cl)c1   \n3   CN(C)c1cccc(C(=S)NN)c1.Cl   \n4                  Nc1ccccc1S   \n\n                                     reaction_smiles  \\\n0  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...   \n1  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...   \n2  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...   \n3  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...   \n4  O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...   \n\n                         reaction_smiles_atom_mapped  ...  binary_H  scaled_A  \\\n0  F[B-](F)(F)[C:2]([c:1]1[cH:13][cH:15][c:17]([C...  ...       1.0  2.406501   \n1  F[B-](F)(F)[C:2]([c:1]1[cH:13][cH:15][c:17]([C...  ...       0.0  0.378474   \n2  F[B-](F)(F)[C:2]([c:1]1[cH:13][cH:15][c:17]([C...  ...       0.0  0.921776   \n3  F[B-](F)(F)[C:2]([c:1]1[cH:13][cH:15][c:17]([C...  ...       1.0  2.117499   \n4  F[B-](F)(F)[C:2]([c:1]1[cH:16][cH:18][c:20]([C...  ...       1.0  2.376621   \n\n   scaled_B  scaled_C  scaled_D  scaled_E  scaled_F  scaled_G  scaled_H  \\\n0  1.281399  0.282070  0.000000  0.413064  0.234782  5.510721  0.290641   \n1  0.928819  0.237341  0.000000  0.064908  0.342595  5.754573  0.000000   \n2  0.869821  0.041536  0.000000  0.000000  0.294589  5.655978  0.000000   \n3  2.550850  0.073327  0.000838  0.283949  0.324134  6.655333  0.213819   \n4  0.011747  0.000000  0.001575  0.209161  1.215448  7.303106  0.811990   \n\n   major_A-C  \n0          A  \n1          B  \n2          A  \n3          B  \n4          A  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>experiment_id</th>\n      <th>I_long</th>\n      <th>M_long</th>\n      <th>T_long</th>\n      <th>product_A_smiles</th>\n      <th>I_smiles</th>\n      <th>M_smiles</th>\n      <th>T_smiles</th>\n      <th>reaction_smiles</th>\n      <th>reaction_smiles_atom_mapped</th>\n      <th>...</th>\n      <th>binary_H</th>\n      <th>scaled_A</th>\n      <th>scaled_B</th>\n      <th>scaled_C</th>\n      <th>scaled_D</th>\n      <th>scaled_E</th>\n      <th>scaled_F</th>\n      <th>scaled_G</th>\n      <th>scaled_H</th>\n      <th>major_A-C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10578</td>\n      <td>Ph023</td>\n      <td>Mon017</td>\n      <td>TerTH010</td>\n      <td>CC(C)(C)OC(=O)CC[C@@H](Cc1nnc(C=Cc2ccccc2)s1)N...</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]</td>\n      <td>CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O</td>\n      <td>Cl.NNC(=S)/C=C/c1ccccc1</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...</td>\n      <td>F[B-](F)(F)[C:2]([c:1]1[cH:13][cH:15][c:17]([C...</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.406501</td>\n      <td>1.281399</td>\n      <td>0.282070</td>\n      <td>0.000000</td>\n      <td>0.413064</td>\n      <td>0.234782</td>\n      <td>5.510721</td>\n      <td>0.290641</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10579</td>\n      <td>Ph023</td>\n      <td>Mon017</td>\n      <td>TerTH026</td>\n      <td>CC(C)(C)OC(=O)CC[C@@H](Cc1nnc(-c2cn[nH]c2)s1)N...</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]</td>\n      <td>CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O</td>\n      <td>Cl.NNC(=S)c1cn[nH]c1</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...</td>\n      <td>F[B-](F)(F)[C:2]([c:1]1[cH:13][cH:15][c:17]([C...</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.378474</td>\n      <td>0.928819</td>\n      <td>0.237341</td>\n      <td>0.000000</td>\n      <td>0.064908</td>\n      <td>0.342595</td>\n      <td>5.754573</td>\n      <td>0.000000</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10580</td>\n      <td>Ph023</td>\n      <td>Mon017</td>\n      <td>TerTH015</td>\n      <td>CC(C)(C)OC(=O)CC[C@@H](Cc1nnc(-c2cc(Cl)cc(Cl)c...</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]</td>\n      <td>CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O</td>\n      <td>Cl.NNC(=S)c1cc(Cl)cc(Cl)c1</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...</td>\n      <td>F[B-](F)(F)[C:2]([c:1]1[cH:13][cH:15][c:17]([C...</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.921776</td>\n      <td>0.869821</td>\n      <td>0.041536</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.294589</td>\n      <td>5.655978</td>\n      <td>0.000000</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10581</td>\n      <td>Ph023</td>\n      <td>Mon017</td>\n      <td>TerTH020</td>\n      <td>CN(C)c1cccc(-c2nnc(C[C@H](CCC(=O)OC(C)(C)C)NC(...</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]</td>\n      <td>CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O</td>\n      <td>CN(C)c1cccc(C(=S)NN)c1.Cl</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...</td>\n      <td>F[B-](F)(F)[C:2]([c:1]1[cH:13][cH:15][c:17]([C...</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.117499</td>\n      <td>2.550850</td>\n      <td>0.073327</td>\n      <td>0.000838</td>\n      <td>0.283949</td>\n      <td>0.324134</td>\n      <td>6.655333</td>\n      <td>0.213819</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10584</td>\n      <td>Ph023</td>\n      <td>Mon017</td>\n      <td>TerABT001</td>\n      <td>CC(C)(C)OC(=O)CC[C@@H](Cc1nc2ccccc2s1)NC(=O)c1...</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.[K+]</td>\n      <td>CC(C)(C)OC(=O)CC[C@H]1C[C@]2(ON1)OC1(CCCCC1)OC2=O</td>\n      <td>Nc1ccccc1S</td>\n      <td>O=C(c1ccc(Cl)cc1)[B-](F)(F)F.CC(C)(C)OC(=O)CC[...</td>\n      <td>F[B-](F)(F)[C:2]([c:1]1[cH:16][cH:18][c:20]([C...</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.376621</td>\n      <td>0.011747</td>\n      <td>0.000000</td>\n      <td>0.001575</td>\n      <td>0.209161</td>\n      <td>1.215448</td>\n      <td>7.303106</td>\n      <td>0.811990</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:09:18.518027Z",
     "start_time": "2023-07-23T14:09:18.497664Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0D split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(36389, 4044)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train, idx_test = train_test_split(list(range(len(df))), test_size=0.1, random_state=42)\n",
    "len(idx_train), len(idx_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:11:16.683098Z",
     "start_time": "2023-07-23T14:11:16.674163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with open(DATA_DIR / \"curated_data\" / \"splits\" / \"0D_split\" / \"train_idx.csv\", \"w\") as f:\n",
    "    f.write(\"index\\n\")\n",
    "    f.write(\"\\n\".join([str(i) for i in idx_train]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:13:27.220365Z",
     "start_time": "2023-07-23T14:13:27.210640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with open(DATA_DIR / \"curated_data\" / \"splits\" / \"0D_split\" / \"test_idx.csv\", \"w\") as f:\n",
    "    f.write(\"index\\n\")\n",
    "    f.write(\"\\n\".join([str(i) for i in idx_test]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:13:42.451615Z",
     "start_time": "2023-07-23T14:13:42.444122Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1D split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# note: we are using a RandomState instance (as opposed to an int) because we will call split() 3 times and want a different, but reproducible, random state for each call to split\n",
    "group_splitter = GroupShuffleSplit(n_splits=3, test_size=0.1, random_state=np.random.RandomState(42))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:29:46.485232Z",
     "start_time": "2023-07-23T14:29:46.475662Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "for i, (train_idx, test_idx) in enumerate(group_splitter.split(list(range(len(df))), groups=df[\"I_long\"])):\n",
    "    with open(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / f\"fold_{i}_train_idx.csv\", \"w\") as f:\n",
    "        f.write(\"index\\n\")\n",
    "        f.write(\"\\n\".join([str(i) for i in train_idx]))\n",
    "    with open(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / f\"fold_{i}_test_idx.csv\", \"w\") as f:\n",
    "        f.write(\"index\\n\")\n",
    "        f.write(\"\\n\".join([str(i) for i in test_idx]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:29:46.791915Z",
     "start_time": "2023-07-23T14:29:46.714044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "for i, (train_idx, test_idx) in enumerate(group_splitter.split(list(range(len(df))), groups=df[\"M_long\"])):\n",
    "    with open(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / f\"fold_{i+3}_train_idx.csv\", \"w\") as f:\n",
    "        f.write(\"index\\n\")\n",
    "        f.write(\"\\n\".join([str(i) for i in train_idx]))\n",
    "    with open(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / f\"fold_{i+3}_test_idx.csv\", \"w\") as f:\n",
    "        f.write(\"index\\n\")\n",
    "        f.write(\"\\n\".join([str(i) for i in test_idx]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:29:46.927448Z",
     "start_time": "2023-07-23T14:29:46.870258Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "for i, (train_idx, test_idx) in enumerate(group_splitter.split(list(range(len(df))), groups=df[\"T_long\"])):\n",
    "    with open(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / f\"fold_{i+6}_train_idx.csv\", \"w\") as f:\n",
    "        f.write(\"index\\n\")\n",
    "        f.write(\"\\n\".join([str(i) for i in train_idx]))\n",
    "    with open(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / f\"fold_{i+6}_test_idx.csv\", \"w\") as f:\n",
    "        f.write(\"index\\n\")\n",
    "        f.write(\"\\n\".join([str(i) for i in test_idx]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:29:47.425033Z",
     "start_time": "2023-07-23T14:29:47.374958Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Show statistics for splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0D split: 36389 train, 4044 (10.0%) test\n",
      "\tTraining set 'major_A-C' class A: 53.2%\n",
      "\tTraining set 'major_A-C' class B: 21.9%\n",
      "\tTraining set 'major_A-C' class C: 8.6%\n",
      "\tTraining set 'major_A-C' class no_product: 16.2%\n",
      "\tTest set 'major_A-C' class A: 53.9%\n",
      "\tTest set 'major_A-C' class B: 21.5%\n",
      "\tTest set 'major_A-C' class C: 8.9%\n",
      "\tTest set 'major_A-C' class no_product: 15.7%\n"
     ]
    }
   ],
   "source": [
    "# 0D split\n",
    "lines = []\n",
    "train_idx = pd.read_csv(DATA_DIR / \"curated_data\" / \"splits\" / \"0D_split\" / \"train_idx.csv\")[\"index\"].values\n",
    "test_idx = pd.read_csv(DATA_DIR / \"curated_data\" / \"splits\" / \"0D_split\" / \"test_idx.csv\")[\"index\"].values\n",
    "lines.append(f\"0D split: {len(train_idx)} train, {len(test_idx)} ({len(test_idx)/(len(test_idx)+len(train_idx)):.1%}) test\")\n",
    "for i, item in (df[\"major_A-C\"].iloc[train_idx].value_counts().sort_index() / len(train_idx)).items():\n",
    "    lines.append(f\"\\tTraining set 'major_A-C' class {i}: {item:.1%}\")\n",
    "for i, item in (df[\"major_A-C\"].iloc[test_idx].value_counts().sort_index() / len(test_idx)).items():\n",
    "    lines.append(f\"\\tTest set 'major_A-C' class {i}: {item:.1%}\")\n",
    "# save stats to file\n",
    "with open(DATA_DIR / \"curated_data\" / \"splits\" / \"0D_split\" / \"split_statistics.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "print(\"\\n\".join(lines))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T15:40:06.111835Z",
     "start_time": "2023-07-23T15:40:06.102860Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 35657 train, 4776 (11.8%) test\n",
      "\tTraining set 'major_A-C' class A: 52.3%\n",
      "\tTraining set 'major_A-C' class B: 21.8%\n",
      "\tTraining set 'major_A-C' class C: 9.3%\n",
      "\tTraining set 'major_A-C' class no_product: 16.6%\n",
      "\tTest set 'major_A-C' class A: 60.5%\n",
      "\tTest set 'major_A-C' class B: 22.2%\n",
      "\tTest set 'major_A-C' class C: 4.0%\n",
      "\tTest set 'major_A-C' class no_product: 13.3%\n",
      "Fold 1: 36166 train, 4267 (10.6%) test\n",
      "\tTraining set 'major_A-C' class A: 53.6%\n",
      "\tTraining set 'major_A-C' class B: 21.8%\n",
      "\tTraining set 'major_A-C' class C: 8.8%\n",
      "\tTraining set 'major_A-C' class no_product: 15.7%\n",
      "\tTest set 'major_A-C' class A: 50.1%\n",
      "\tTest set 'major_A-C' class B: 22.2%\n",
      "\tTest set 'major_A-C' class C: 7.5%\n",
      "\tTest set 'major_A-C' class no_product: 20.3%\n",
      "Fold 2: 36895 train, 3538 (8.8%) test\n",
      "\tTraining set 'major_A-C' class A: 53.1%\n",
      "\tTraining set 'major_A-C' class B: 21.8%\n",
      "\tTraining set 'major_A-C' class C: 9.2%\n",
      "\tTraining set 'major_A-C' class no_product: 16.0%\n",
      "\tTest set 'major_A-C' class A: 54.9%\n",
      "\tTest set 'major_A-C' class B: 23.0%\n",
      "\tTest set 'major_A-C' class C: 3.6%\n",
      "\tTest set 'major_A-C' class no_product: 18.4%\n",
      "Fold 3: 35686 train, 4747 (11.7%) test\n",
      "\tTraining set 'major_A-C' class A: 51.5%\n",
      "\tTraining set 'major_A-C' class B: 22.0%\n",
      "\tTraining set 'major_A-C' class C: 9.2%\n",
      "\tTraining set 'major_A-C' class no_product: 17.3%\n",
      "\tTest set 'major_A-C' class A: 66.6%\n",
      "\tTest set 'major_A-C' class B: 20.8%\n",
      "\tTest set 'major_A-C' class C: 4.9%\n",
      "\tTest set 'major_A-C' class no_product: 7.8%\n",
      "Fold 4: 35854 train, 4579 (11.3%) test\n",
      "\tTraining set 'major_A-C' class A: 52.2%\n",
      "\tTraining set 'major_A-C' class B: 22.4%\n",
      "\tTraining set 'major_A-C' class C: 8.9%\n",
      "\tTraining set 'major_A-C' class no_product: 16.5%\n",
      "\tTest set 'major_A-C' class A: 61.5%\n",
      "\tTest set 'major_A-C' class B: 17.4%\n",
      "\tTest set 'major_A-C' class C: 7.3%\n",
      "\tTest set 'major_A-C' class no_product: 13.9%\n",
      "Fold 5: 36615 train, 3818 (9.4%) test\n",
      "\tTraining set 'major_A-C' class A: 51.9%\n",
      "\tTraining set 'major_A-C' class B: 22.5%\n",
      "\tTraining set 'major_A-C' class C: 8.9%\n",
      "\tTraining set 'major_A-C' class no_product: 16.7%\n",
      "\tTest set 'major_A-C' class A: 66.3%\n",
      "\tTest set 'major_A-C' class B: 15.5%\n",
      "\tTest set 'major_A-C' class C: 6.5%\n",
      "\tTest set 'major_A-C' class no_product: 11.6%\n",
      "Fold 6: 35317 train, 5116 (12.7%) test\n",
      "\tTraining set 'major_A-C' class A: 54.6%\n",
      "\tTraining set 'major_A-C' class B: 20.7%\n",
      "\tTraining set 'major_A-C' class C: 8.4%\n",
      "\tTraining set 'major_A-C' class no_product: 16.2%\n",
      "\tTest set 'major_A-C' class A: 44.0%\n",
      "\tTest set 'major_A-C' class B: 29.7%\n",
      "\tTest set 'major_A-C' class C: 10.4%\n",
      "\tTest set 'major_A-C' class no_product: 15.8%\n",
      "Fold 7: 35957 train, 4476 (11.1%) test\n",
      "\tTraining set 'major_A-C' class A: 53.5%\n",
      "\tTraining set 'major_A-C' class B: 23.0%\n",
      "\tTraining set 'major_A-C' class C: 9.0%\n",
      "\tTraining set 'major_A-C' class no_product: 14.5%\n",
      "\tTest set 'major_A-C' class A: 51.1%\n",
      "\tTest set 'major_A-C' class B: 13.1%\n",
      "\tTest set 'major_A-C' class C: 5.9%\n",
      "\tTest set 'major_A-C' class no_product: 29.9%\n",
      "Fold 8: 36110 train, 4323 (10.7%) test\n",
      "\tTraining set 'major_A-C' class A: 54.6%\n",
      "\tTraining set 'major_A-C' class B: 21.1%\n",
      "\tTraining set 'major_A-C' class C: 8.5%\n",
      "\tTraining set 'major_A-C' class no_product: 15.8%\n",
      "\tTest set 'major_A-C' class A: 42.4%\n",
      "\tTest set 'major_A-C' class B: 28.0%\n",
      "\tTest set 'major_A-C' class C: 10.5%\n",
      "\tTest set 'major_A-C' class no_product: 19.1%\n"
     ]
    }
   ],
   "source": [
    "# 1D split\n",
    "lines = []\n",
    "for i in range(9):\n",
    "    train_idx = pd.read_csv(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / f\"fold_{i}_train_idx.csv\")[\"index\"].values\n",
    "    test_idx = pd.read_csv(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / f\"fold_{i}_test_idx.csv\")[\"index\"].values\n",
    "    lines.append(f\"Fold {i}: {len(train_idx)} train, {len(test_idx)} ({len(test_idx)/(len(test_idx)+len(train_idx)):.1%}) test\")\n",
    "    for i, item in (df[\"major_A-C\"].iloc[train_idx].value_counts().sort_index() / len(train_idx)).items():\n",
    "        lines.append(f\"\\tTraining set 'major_A-C' class {i}: {item:.1%}\")\n",
    "    for i, item in (df[\"major_A-C\"].iloc[test_idx].value_counts().sort_index() / len(test_idx)).items():\n",
    "        lines.append(f\"\\tTest set 'major_A-C' class {i}: {item:.1%}\")\n",
    "\n",
    "# save stats to file\n",
    "with open(DATA_DIR / \"curated_data\" / \"splits\" / \"1D_split\" / \"split_statistics.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "print(\"\\n\".join(lines))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T15:39:10.877429Z",
     "start_time": "2023-07-23T15:39:10.837874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
