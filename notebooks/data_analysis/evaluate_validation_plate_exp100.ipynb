{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Evaluation of the 0D validation plate (exp100/JG405)\n",
    "\n",
    "We have previously made predictions for this plate and now have obtained the analytical data.\n",
    "We want to evaluate how well our predictions align with the experiment.\n",
    "\n",
    "The plate was originally designed using the model trained on 2023-09-05 data and it was designed such that all attempted syntheses were predicted to work by the model. In the meantime we had to make minor changes in the data and retrain on the updated 2023-12-20 data. While the predictions of the two models align well (ca. 97% accuracy across the VL across products), we need to account for the differences.\n",
    "\n",
    "There is no completely unbiased way to do this. The best is to just drop all of the cases where the new model predicts a negative value and evaluate the precision based on the remaining values. This is slightly biased because the compounds were \"pre-selected\" by the earlier model. Fortunately the influence of this will be small since the models align so well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(pathlib.Path().resolve().parents[1]))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "from src.definitions import DATA_DIR\n",
    "from src.util.db_utils import SynFermDatabaseConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load plate data used for inference (we only need the vl_id to match with the experimental results)\n",
    "val_plate = pd.read_csv(DATA_DIR / \"curated_data\" / \"validation_plates.csv\")[[\"vl_id\"]]\n",
    "val_plate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the predictions\n",
    "preds = pd.read_csv(DATA_DIR / \"curated_data\" / \"validation_plates_pred_2024-04-18.csv\")\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge plate data with preds\n",
    "preds = pd.concat([val_plate, preds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = SynFermDatabaseConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = con.con.execute(\"SELECT id, vl_id, well, initiator_long, monomer_long, terminator_long, product_A_lcms_ratio, product_B_lcms_ratio, product_C_lcms_ratio FROM experiments WHERE exp_nr = 100 AND (valid NOT LIKE '%ERROR%' OR valid IS NULL);\").fetchall()\n",
    "result = pd.DataFrame(res, columns=[\"id\", \"vl_id\", \"well\", \"initiator_long\", \"monomer_long\", \"terminator_long\", \"product_A_lcms_ratio\", \"product_B_lcms_ratio\", \"product_C_lcms_ratio\"])\n",
    "result[\"binary_A\"] = (result[\"product_A_lcms_ratio\"] > 0).astype(int)\n",
    "result[\"binary_B\"] = (result[\"product_B_lcms_ratio\"] > 0).astype(int)\n",
    "result[\"binary_C\"] = (result[\"product_C_lcms_ratio\"] > 0).astype(int)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine predictions and results\n",
    "comb = result.merge(preds, on=\"vl_id\", how=\"left\")\n",
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any compounds that the new model would not have predicted to work?\n",
    "comb.loc[comb[\"pred_A\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Side note on bias through model update\n",
    "Turns out there are only 1/150 instances where the two models disagree. We drop this data point before we continue the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = comb.loc[comb[\"pred_A\"] == 1]\n",
    "len(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate for binary_A: What was the models prospective precision?\n",
    "len(comb.loc[comb[\"binary_A\"] == 1]) / len(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate for binary_B\n",
    "print(f'Accuracy: {accuracy_score(comb[\"binary_B\"], comb[\"pred_B\"]):.2%}')\n",
    "print(f'Precision: {precision_score(comb[\"binary_B\"], comb[\"pred_B\"]):.2%}')\n",
    "print(f'Recall: {recall_score(comb[\"binary_B\"], comb[\"pred_B\"]):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate for binary_C\n",
    "print(f'Accuracy: {accuracy_score(comb[\"binary_C\"], comb[\"pred_C\"]):.2%}')\n",
    "print(f'Precision: {precision_score(comb[\"binary_C\"], comb[\"pred_C\"]):.2%}')\n",
    "print(f'Recall: {recall_score(comb[\"binary_C\"], comb[\"pred_C\"]):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the wells that had valid reactions in the plate layout\n",
    "# n.b. we ignore the right half of the plate b/c all of that was invalid (oxalic acid transfer error)\n",
    "arr = np.zeros((16, 10), dtype=int)\n",
    "\n",
    "for well in comb[\"well\"]:\n",
    "    row = ord(well[0]) - 65\n",
    "    col = int(well[1:]) - 3\n",
    "    arr[row, col] = 1\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette([\"#e42536\", \"#f0f0f0\", \"#5790fc\"])\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where was A predicted correctly?\n",
    "arr = np.zeros((16, 10), dtype=int)\n",
    "\n",
    "for i, dfrow in comb.iterrows():\n",
    "    row = ord(dfrow[\"well\"][0]) - 65\n",
    "    col = int(dfrow[\"well\"][1:]) - 3\n",
    "    if dfrow[\"pred_A\"] == dfrow[\"binary_A\"]:\n",
    "        arr[row, col] = 1\n",
    "    else:\n",
    "        arr[row, col] = -1\n",
    "plt.figure(figsize=(1.2, 1))\n",
    "ax = sns.heatmap(arr, center=0, cmap=palette, cbar=False, linewidths=0.1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"exp100_precisionA.svg\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where was B predicted correctly?\n",
    "arr = np.zeros((16, 10), dtype=int)\n",
    "\n",
    "for i, dfrow in comb.iterrows():\n",
    "    row = ord(dfrow[\"well\"][0]) - 65\n",
    "    col = int(dfrow[\"well\"][1:]) - 3\n",
    "    if dfrow[\"pred_B\"] == dfrow[\"binary_B\"]:\n",
    "        arr[row, col] = 1\n",
    "    else:\n",
    "        arr[row, col] = -1\n",
    "sns.heatmap(arr, center=0, cmap=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where was C predicted correctly?\n",
    "arr = np.zeros((16, 10), dtype=int)\n",
    "\n",
    "for i, dfrow in comb.iterrows():\n",
    "    row = ord(dfrow[\"well\"][0]) - 65\n",
    "    col = int(dfrow[\"well\"][1:]) - 3\n",
    "    if dfrow[\"pred_C\"] == dfrow[\"binary_C\"]:\n",
    "        arr[row, col] = 1\n",
    "    else:\n",
    "        arr[row, col] = -1\n",
    "sns.heatmap(arr, center=0, cmap=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
